Installing TensorFlow on HPC Cluster without Root Access
(Including Installing Python 3, Java, Bazel, Git, Curl, and Expat, on HPC Cluster without Root Access)

Environment: Red Hat Enterprise Linux Server release 7.6
HPC batch system: PBS Pro

Installing TensorFlow and Testing Notes:
TensorFlow (https://www.tensorflow.org/) is a free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks. 
Environment required (a) GCC 4.8. (b) Python 3 and Pip 3. (c) Java OpenJDK 8. (d) Bazel. (e) Git, Curl, and Expat. (f) Bazel. (e) TensorFlow. (f) Keras
In the following pages, we assume that you want to install the software in a directory named “software” inside your home directory.

1. Python 3 and Pip 3
Go to where you want to install python3:
cd /gpfs1/home/USERNAME/software
mkdir python3
Download Python 3 installation package using wget:
wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tar.xz
Unzip Python3 installation package using tar:
tar xvf Python-3.7.4.tar.xz
Go to the directory having the configure file: 
cd Python-3.7.4
Configure and specify where Python3 will be installed: 
./configure --prefix=/gpfs1/home/USERNAME/software/python3
Notice: The prefix option, it is mandatory for this to work. The value of the prefix option is to specify where to put the related output of the make command, by default it is in the /usr/local/ and we don't want that, so we use our own customized directory.
Build: 
make
Install:
make install
Go to /gpfs1/home/USERNAME, then update the environment variables:
cd /gpfs1/home/USERNAME/
Then add this line to ~/.bash_profile
export PATH=/gpfs1/home/USERNAME/software/python3/bin:$PATH
Refresh the current session by entering the following command:
cd /gpfs1/home/USERNAME/
source .bash_profile
Notice: The pip3 is also installed 
Install the TensorFlow package dependencies:
pip3 install -U --user six numpy wheel setuptools mock future
pip3 install -U --user keras_applications==1.0.6 --no-deps
pip3 install -U --user keras_preprocessing==1.0.5 --no-deps

2. Java

Java downloads: (Sign up needed)
https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
Download jdk-8u221-linux-x64.tar.gz
Go to where you want to install Java:
cd /gpfs1/home/USERNAME/software
mkdir java-src
cd java-src
using WinSCP or other tools to transfer package jdk-8u221-linux-x64.tar.gz to /gpfs1/home/USERNAME/software/java-src
tar zxvf jdk-8u221-linux-x64.tar.gz
cd jdk1.8.0_221/
cd bin/
Go to /gpfs1/home/USERNAME, then update the environment variables:
cd /gpfs1/home/USERNAME/
Then add this line to ~/.bash_profile
export JAVA_HOME=/gpfs1/home/USERNAME/software/java-src/jdk1.8.0_221
export JAVA_JRE=/gpfs1/home/USERNAME/software/java-src/jdk1.8.0_221/jre
export PATH=/gpfs1/home/USERNAME/software/java-src/jdk1.8.0_221/bin:$HOME/software/java-src/jdk1.8.0_221/jre/bin:$PATH
Refresh the current session by entering the following command:
cd /gpfs1/home/USERNAME/
source .bash_profile
3. Bazel

Go to where you want to install Bazel:
cd /gpfs1/home/USERNAME/software
mkdir bazel-src
cd bazel-src
Download Bazel installation package using wget:
wget https://github.com/bazelbuild/bazel/releases/download/0.24.1/bazel-0.24.1-dist.zip
Create a folder to put binary file:
mkdir bin
Unzip Python3 installation package using unzip:
unzip bazel-0.24.1-dist.zip -d bazel-0.24.1-dist
cd bazel-0.24.1-dist/
Create and edit correct pbs file to submit bazel compile job: 
touch bazel-compile.pbs
Use vim or nano to edit this file. 

#!/bin/bash
#PBS -q default
#PBS -N bazel-compile
#PBS -l select=1:mem=32GB:ncpus=10 
#PBS -l walltime=16:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
/gpfs1/home/USERNAME/software/bazel-src/bazel-0.24.1-dist/compile.sh

Submit the bazel-compile.pbs job:
qsub  bazel-compile.pbs

The output shows “Build successful! Binary is here: /gpfs1/home/USERNAME/software/bazel-src/bazel-0.24.1-dist/output/bazel”. Then copy the binary file:
 cp -rf /gpfs1/home/USERNAME/software/bazel-src/bazel-0.24.1-dist/output/bazel /gpfs1/home/USERNAME/software/bazel-src/bin/
Go to /gpfs1/home/USERNAME, then update the environment variables:
cd /gpfs1/home/USERNAME/
Then add this line to ~/.bash_profile
export PATH=/gpfs1/home/USERNAME/software/bazel-src/bin:$PATH
Refresh the current session by entering the following command:
cd /gpfs1/home/USERNAME/
source .bash_profile

4. Git, Curl, and Expat
Note: The current Git version on Cluster may not support the installation of TensorFlow. We install a newer version if necessary.
Go to where you want to install Git, Curl, and Expat, download installation package, configure, and make&make install:
cd /gpfs1/home/USERNAME/software
mkdir curl-src expat-src git-src
[USERNAME@login000x software]$ curl-src
[USERNAME@login000x curl-src]$ wget https://curl.haxx.se/download/curl-7.47.1.tar.gz
[USERNAME@login000x curl-src]$ mkdir curl_install
[USERNAME@login000x curl-src]$ tar zxvf curl-7.47.1.tar.gz
[USERNAME@login000x curl-src]$ cd curl-7.47.1
[USERNAME@login000x curl-7.47.1]$ ./configure –prefix=$HOME/software/curl-src/curl_install
[USERNAME@login000x curl-7.47.1]$ make
[USERNAME@login000x curl-7.47.1]$ make install

[USERNAME@login000x software]$ cd expat-src
[USERNAME@login000x expat-src]$ mkdir expat_install
[USERNAME@login000x expat-src]$ wget http://downloads.sourceforge.net/expat/expat-2.1.0.tar.gz
[USERNAME@login000x expat-src]$ tar zxvf expat-2.1.0.tar.gz
[USERNAME@login000x expat-src]$ cd expat-2.1.0
[USERNAME@login000x expat-2.1.0]$ ./configure --prefix=$HOME/software/expat-src/expat_install
[USERNAME@login000x expat-2.1.0]$ make
[USERNAME@login000x expat-2.1.0]$ make install

[USERNAME@login000x software]$ cd git-src
[USERNAME@login000x git-src]$ mkdir git_install
[USERNAME@login000x git-src]$ wget https://github.com/git/git/archive/v2.6.4.tar.gz
[USERNAME@login000x git-src]$ tar zxvf v2.6.4.tar.gz
[USERNAME@login000x git-src]$ cd git-2.6.4
[USERNAME@login000x git-2.6.4]$ make configure
[USERNAME@login000x git-2.6.4]$ ./configure --prefix=/gpfs1/home/USERNAME/software/git-src/git_install/git --with-curl=/gpfs1/home/USERNAME/software/curl-src/curl_install --with-expat=/gpfs1/home/USERNAME/software/expat-src/expat_install
[USERNAME@login000x git-2.6.4]$ make
[USERNAME@login000x git-2.6.4]$ make install

Go to /gpfs1/home/USERNAME, then update the environment variables:
cd /gpfs1/home/USERNAME/
Then add this line to ~/.bash_profile
export PATH=$HOME/software/bazel-src/bin:$PATH
export PATH=$HOME/software/git-src/git_install/git/bin:$PATH
Refresh the current session by entering the following command:
cd /gpfs1/home/USERNAME/
source .bash_profile

5. Installing TensorFlow 1.14 (CPU version)
[USERNAME@login000x software]$ mkdir tensorflow-src
[USERNAME@login000x software]$ cd tensorflow-src/
[USERNAME@login000x tensorflow-src]$ git clone https://github.com/tensorflow/tensorflow.git
[USERNAME@login000x tensorflow-src]$ cd tensorflow
[USERNAME@login000x tensorflow]$ git checkout r1.14
[USERNAME@login000x tensorflow]$ ./configure
Example:
Please specify the location of python.
/gpfs1/home/USERNAME/software/python3/bin/python3.7
Please input the desired Python library path to use.  Default is [gpfs1/home/USERNAME/software/python3/dist-packages]
“click enter”
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n “click enter”
Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n “click enter”
Do you wish to build TensorFlow with XLA JIT support? [y/N]: N “click enter”

Create and edit correct pbs file to submit TensorFlow build process:
[USERNAME@login000x tensorflow]$ touch tensorflow-build.pbs
Use vim or nano to edit this file.

#!/bin/bash
#PBS -q default
#PBS -N bazel-compile
#PBS -l select=1:mem=32GB:ncpus=10 
#PBS -l walltime=16:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

Submit the tensorflow-build.pbs job:
qsub  tensorflow-build.pbs


[USERNAME@login000x tensorflow]$ touch tensorflow-whl.pbs
Use vim or nano to edit this file.

#!/bin/bash
#PBS -q default
#PBS -N bazel-compile
#PBS -l select=1:mem=3GB:ncpus=2 
#PBS -l walltime=16:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
/gpfs1/home/USERNAME/software/tensorflow-src/tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package /gpfs1/home/USERNAME/software/tensorflow-src/tensorflow_pkg

pip3 install /gpfs1/home/USERNAME/software/tensorflow-src/tensorflow_pkg/tensorflow-1.14.1-cp37-cp37m-linux_x86_64.whl

Submit the tensorflow-whl.pbs job:
qsub  tensorflow-whl.pbs

6. Keras
Then, install Keras:
pip3 install -U --user keras

7. Installing TensorFlow 2.0 (CPU version)
[USERNAME@login000x software]$ mkdir tensorflow-src
[USERNAME@login000x software]$ cd tensorflow-src/
[USERNAME@login000x tensorflow-src]$ git clone https://github.com/tensorflow/tensorflow.git
[USERNAME@login000x tensorflow-src]$ cd tensorflow
[USERNAME@login000x tensorflow]$ git checkout r2.0
[USERNAME@login000x tensorflow]$ ./configure
Example:
Please specify the location of python.
/gpfs1/home/USERNAME/software/python3/bin/python3.7
Please input the desired Python library path to use.  Default is [gpfs1/home/USERNAME/software/python3/dist-packages]
“click enter”
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n “click enter”
Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n “click enter”
Do you wish to build TensorFlow with XLA JIT support? [y/N]: N “click enter”

Create and edit correct pbs file to submit TensorFlow build process to Cluster’s queue system:
[USERNAME@login000x tensorflow]$ touch tensorflow-build.pbs
Use vim or nano to edit this file.
#!/bin/bash
#PBS -q default
#PBS -N bazel-compile
#PBS -l select=1:mem=32GB:ncpus=10 
#PBS -l walltime=16:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
bazel build --config=v2 //tensorflow/tools/pip_package:build_pip_package

[USERNAME@login000x tensorflow]$ touch tensorflow-whl.pbs
Use vim or nano to edit this file.

#!/bin/bash
#PBS -q default
#PBS -N bazel-compile
#PBS -l select=1:mem=3GB:ncpus=2 
#PBS -l walltime=16:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
/gpfs1/home/USERNAME/software/tensorflow-src/tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package /gpfs1/home/USERNAME/software/tensorflow-src/tensorflow_pkg

pip3 install /gpfs1/home/USERNAME/software/tensorflow-src/tensorflow_pkg/tensorflow-version-tags.whl
(replace the tensorflow-version-tags)

Then, install Keras:
pip3 install -U --user keras

8. Testing TensorFlow1.14 (CPU version)
8.1 Test 1
File: tf_test_1.py:
import tensorflow as tf
# Creates a grapg
with tf.device('/cpu:0'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print(sess.run(c))

Submit the job:
qsub tf_test_1.pbs
--------------- file tf_test_1.pbs -----------------
#!/bin/bash
#PBS -q default
#PBS -N tf_test_1
#PBS -j oe
#PBS -l select=1:mem=2gb:ncpus=1
#PBS -l walltime=08:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
python3 tf_test_1.py

The output shows it works:
tf_test_1.o{job_ID}

8.2 Test 2
File: tf_test_2.py:

from __future__ import print_function
import tempfile
import shutil

# Import MNIST data
from tensorflow.examples.tutorials.mnist import input_data
dirpath = tempfile.mkdtemp() # make temporary directory to store MNIST dataset files
mnist = input_data.read_data_sets(dirpath, one_hot=False)

import tensorflow as tf

# Parameters
learning_rate = 0.1
num_steps = 1000
batch_size = 128
display_step = 100

# Network Parameters
n_hidden_1 = 256 # 1st layer number of neurons
n_hidden_2 = 256 # 2nd layer number of neurons
num_input = 784 # MNIST data input (img shape: 28*28)
num_classes = 10 # MNIST total classes (0-9 digits)
# Define the neural network
def neural_net(x_dict):
    # TF Estimator input is a dict, in case of multiple inputs
    x = x_dict['images']
    # Hidden fully connected layer with 256 neurons
    layer_1 = tf.layers.dense(x, n_hidden_1)
    # Hidden fully connected layer with 256 neurons
    layer_2 = tf.layers.dense(layer_1, n_hidden_2)
    # Output fully connected layer with a neuron for each class
    out_layer = tf.layers.dense(layer_2, num_classes)
    return out_layer


# Define the model function (following TF Estimator Template)
def model_fn(features, labels, mode):
    # Build the neural network
    logits = neural_net(features)

    # Predictions
    pred_classes = tf.argmax(logits, axis=1)
    pred_probas = tf.nn.softmax(logits)

    # If prediction mode, early return
if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)


# Define loss and optimizer
    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(
        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = optimizer.minimize(loss_op,
                                  global_step=tf.train.get_global_step())

    # Evaluate the accuracy of the model
    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)

    # TF Estimators requires to return a EstimatorSpec, that specify
    # the different ops for training, evaluating, ...
    estim_specs = tf.estimator.EstimatorSpec(
        mode=mode,
        predictions=pred_classes,
        loss=loss_op,
        train_op=train_op,
        eval_metric_ops={'accuracy': acc_op})

    return estim_specs
# Build the Estimator
model = tf.estimator.Estimator(model_fn)

# Define the input function for training
input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'images': mnist.train.images}, y=mnist.train.labels,
    batch_size=batch_size, num_epochs=None, shuffle=True)

# Train the Model
model.train(input_fn, steps=num_steps)

# Evaluate the Model
# Define the input function for evaluating
input_fn = tf.estimator.inputs.numpy_input_fn(
    x={'images': mnist.test.images}, y=mnist.test.labels,
    batch_size=batch_size, shuffle=False)
# Use the Estimator 'evaluate' method
e = model.evaluate(input_fn)

print("Testing Accuracy:", e['accuracy'])
shutil.rmtree(dirpath) # remove temporary directory with MNIST dataset files

Submit the job:
qsub tf_test_2.pbs
--------------- file tf_test_2.pbs -----------------
#!/bin/bash
#PBS -q default
#PBS -N tf_test_2
#PBS -j oe
#PBS -l select=1:mem=2gb:ncpus=1
#PBS -l walltime=08:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
python3 tf_test_2.py

The output shows it works:
tf_test_2.o{job_ID}



9. Testing TensorFlow2.0 (CPU version)
9.1 Test 1
File: tf2_test.py:
from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow
#try:
  # %tensorflow_version only exists in Colab.
  #%tensorflow_version 2.x
#except Exception:
#  pass

import tensorflow as tf

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test, y_test)



Submit the job:
qsub tf2_test.pbs
--------------- file mnist_cnn.pbs -----------------
#!/bin/bash
#PBS -q default
#PBS -N tf2_test
#PBS -j oe
##changes the values as needed
#PBS -l select=1:mem=4gb:ncpus=1
#PBS -l walltime=08:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}

python3 tf2_test.py

The output shows it works:
tf2_test.o{job_ID}

10. Test Keras
File: mnist_cnn.py:
from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

batch_size = 128
num_classes = 10
epochs = 12

# input image dimensions
img_rows, img_cols = 28, 28

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])



Submit the job:
qsub mnist_cnn.pbs
--------------- file mnist_cnn.pbs -----------------
#!/bin/bash
#PBS -q default
#PBS -N mnist_cnn
#PBS -j oe
#PBS -l select=1:mem=32gb:ncpus=1
#PBS -l walltime=24:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
python3 mnist_cnn.py

The output shows it works:
mnist_cnn.o{job_ID}

11. Installing TensorFlow 1.14 (GPU version)
Tested build configurations from https://www.tensorflow.org/install/source#install_gpu_support_optional_linux_only
     
Note: Before installing TensorFlow, please check versions of these tools.

[USERNAME@login000x software]$ mkdir tensorflow-gpu
[USERNAME@login000x software]$ cd tensorflow-gpu/
[USERNAME@login000x tensorflow-gpu]$ git clone https://github.com/tensorflow/tensorflow.git
[USERNAME@login000x tensorflow-gpu]$ cd tensorflow
[USERNAME@login000x tensorflow]$ git checkout r1.14
[USERNAME@login000x tensorflow]$ ./configure
Example:
Please specify the location of python.
/gpfs1/home/USERNAME/software/python3/bin/python3.7
Please input the desired Python library path to use.  Default is [gpfs1/home/USERNAME/software/python3/dist-packages]
“click enter”
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n “click enter”
Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n “click enter”
Do you wish to build TensorFlow with XLA JIT support? [y/N]: N “click enter”
Could not find any cuda.h matching version '' in any subdirectory:
        '' 'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
of:
        '/cm/local/apps/cmd/lib'
        '/cm/local/apps/mysql++/current/lib'
        '/lib'
        '/lib64'
        '/opt/ibutils/lib64'
        '/opt/mellanox/hcoll/lib'
        '/opt/mellanox/mxm/lib'
        '/opt/mellanox/sharp/lib'
        '/usr'
        '/usr/lib64//bind9-export'
        '/usr/lib64/atlas'
        '/usr/lib64/mysql'
Asking for detailed CUDA configuration...
Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: “click enter”
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: “click enter”
Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: “click enter”
Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: gpfs1/apps/centos7/opt/CUDA_10.0.130, /gpfs1/apps/centos7/opt/CUDA_10.0.130/lib64, /gpfs1/apps/centos7/opt/CUDA_10.0.130/include
Found CUDA 10.0 in:
    /gpfs1/apps/centos7/opt/CUDA_10.0.130/lib64
    /gpfs1/apps/centos7/opt/CUDA_10.0.130/include
Found cuDNN 7 in:
    /gpfs1/apps/centos7/opt/CUDA_10.0.130/lib64
    /gpfs1/apps/centos7/opt/CUDA_10.0.130/include
Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]:
 6.0
Do you want to use clang as CUDA compiler? [y/N]: N “click enter”
nvcc will be used as CUDA compiler.
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: “click enter”
Do you wish to build TensorFlow with MPI support? [y/N]: N “click enter”
No MPI support will be enabled for TensorFlow.
Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native -Wno-sign-compare]: “click enter”
Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N “click enter”
Not configuring the WORKSPACE for Android builds.
Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=gdr            # Build with GDR support.
        --config=verbs          # Build with libverbs support.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=noignite       # Disable Apache Ignite support.
        --config=nokafka        # Disable Apache Kafka support.
        --config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished

Create and edit correct pbs file to submit TensorFlow build process:
[USERNAME@login000x tensorflow]$ touch tensorflow-build.pbs
Use vim or nano to edit this file.


#!/bin/bash
#PBS -q default
#PBS -N bazel-compile
#PBS -l select=1:mem=32GB:ncpus=10 (replace with #PBS -l mem=32GB:ncpus=10  and  #PBS -l host=node00xx )
#PBS -l walltime=16:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
module load CUDAToolkit/10.0
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

Submit the tensorflow-build.pbs job:
qsub  tensorflow-build.pbs


[USERNAME@login000x tensorflow]$ touch tensorflow-whl.pbs
Use vim or nano to edit this file.

#!/bin/bash
#PBS -q default
#PBS -N bazel-compile
#PBS -l select=1:mem=3GB:ncpus=2 (replace with #PBS -l mem=3GB:ncpus=2  and  #PBS -l host=node00xx ) 
#PBS -l walltime=16:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}
/gpfs1/home/USERNAME/software/tensorflow-gpu/tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package /gpfs1/home/USERNAME/software/tensorflow-gpu/tensorflow_pkg

pip3 install /gpfs1/home/USERNAME/software/tensorflow-gpu/tensorflow_pkg/tensorflow-1.14.1-cp37-cp37m-linux_x86_64.whl

Submit the tensorflow-whl.pbs job:
qsub  tensorflow-whl.pbs

12. Testing TensorFlow1.14 (GPU version)
12.1 Test 1
File: test_2gpu.py:
import tensorflow as tf
# Creates a graph.
c = []
for d in ['/device:GPU:0', '/device:GPU:1']:
  with tf.device(d):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])
    c.append(tf.matmul(a, b))
with tf.device('/cpu:0'):
  sum = tf.add_n(c)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print(sess.run(sum))

Submit the job:
qsub tf_test_1.pbs
--------------- file tf_test_1.pbs -----------------
#!/bin/bash
#PBS -q gpu-devel
#PBS -N tf-gpu_test_1
#PBS -l select=1:host=node_xxx:mem=2G
#PBS -l walltime=08:00:00
#PBS -W group_list=xxx
cd ${PBS_O_WORKDIR}

module load CUDAToolkit/10.0

#python3 test.py
python3 test_2gpu.py

The output shows it works:
tf-gpu_test_1.o{job_ID}
tf-gpu_test_1.e{job_ID}
--------------- tf-gpu_test_1.o{job_ID}-----------------
 [[ 44.  56.]
 [ 98. 128.]]
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla P100-SXM2-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla P100-SXM2-16GB, pci bus id: 0000:0a:00.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:4 -> device: 4, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8c:00.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:5 -> device: 5, name: Tesla P100-SXM2-16GB, pci bus id: 0000:8d:00.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:6 -> device: 6, name: Tesla P100-SXM2-16GB, pci bus id: 0000:90:00.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:7 -> device: 7, name: Tesla P100-SXM2-16GB, pci bus id: 0000:91:00.0, compute capability: 6.0
MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:1
AddN: (AddN): /job:localhost/replica:0/task:0/device:CPU:0
Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_2: (Const): /job:localhost/replica:0/task:0/device:GPU:1
Const_3: (Const): /job:localhost/replica:0/task:0/device:GPU:1

13. Uninstall TensorFlow
[USERNAME@login000x]$ pip3 uninstall tensorflow 
Example:
Example1:
[USERNAME@login0001 python3]$ pip3 uninstall tensorflow
Uninstalling tensorflow-2.0.0rc0:
  Would remove:
    /gpfs1/home/USERNAME/software/python3/bin/saved_model_cli
    /gpfs1/home/USERNAME/software/python3/bin/tensorboard
    /gpfs1/home/USERNAME/software/python3/bin/tf_upgrade_v2
    /gpfs1/home/USERNAME/software/python3/bin/tflite_convert
    /gpfs1/home/USERNAME/software/python3/bin/toco
    /gpfs1/home/USERNAME/software/python3/bin/toco_from_protos
    /gpfs1/home/USERNAME/software/python3/lib/python3.7/site-packages/tensorflow-2.0.0rc0.dist-info/*
    /gpfs1/home/USERNAME/software/python3/lib/python3.7/site-packages/tensorflow/*
    /gpfs1/home/USERNAME/software/python3/lib/python3.7/site-packages/tensorflow_core/*
Proceed (y/n)? y “Click Enter”
  Successfully uninstalled tensorflow-2.0.0rc0

Example2:
[USERNAME@login0001 tensorgpu]$ pip3 uninstall tensorflow
Uninstalling tensorflow-1.14.1:
  Would remove:
    /gpfs1/home/USERNAME/software/python3/bin/freeze_graph
    /gpfs1/home/USERNAME/software/python3/bin/saved_model_cli
    /gpfs1/home/USERNAME/software/python3/bin/tensorboard
    /gpfs1/home/USERNAME/software/python3/bin/tf_upgrade_v2
    /gpfs1/home/USERNAME/software/python3/bin/tflite_convert
    /gpfs1/home/USERNAME/software/python3/bin/toco
    /gpfs1/home/USERNAME/software/python3/bin/toco_from_protos
    /gpfs1/home/USERNAME/software/python3/lib/python3.7/site-packages/tensorflow-1.14.1.dist-info/*
    /gpfs1/home/USERNAME/software/python3/lib/python3.7/site-packages/tensorflow/*
Proceed (y/n)?y “Click Enter”
Successfully uninstalled tensorflow-1.14.1



